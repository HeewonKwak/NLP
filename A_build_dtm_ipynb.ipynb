{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "A_build_dtm.ipynb의 사본",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DUMLRJgd4oNk"
      },
      "source": [
        "# Building a Document-Term Matrix from scratch\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8psD-b0p4pAw"
      },
      "source": [
        "# install & import the libraries needed\n",
        "# !pip3 install pandas\n",
        "# !pip3 install scikit-learn\n",
        "from typing import List\n",
        "import pandas as pd\n",
        "from sklearn.metrics.pairwise import cosine_similarity"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GAlToICi4uFl"
      },
      "source": [
        "# A mini corpus to play with\n",
        "CORPUS = [\n",
        "    'this is the first document',\n",
        "    'this is the second document',\n",
        "    'and this is the third document',\n",
        "    'is this the first document ?'\n",
        "]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lZUyijMYd7ek"
      },
      "source": [
        "def tf(corpus: str, voca: str):\n",
        "    ### TODO 1 ### \n",
        "    # count the frequency of term in doc. hint: str.count()\n",
        "    tf = []\n",
        "    for i in corpus:\n",
        "      ltf = []\n",
        "      for j in voca:\n",
        "        ltf.append(i.count(j))\n",
        "      tf.append(ltf)\n",
        "    ##############\n",
        "    return tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RkuFhDyhgbkq",
        "outputId": "040d0166-fef9-46d3-d30b-078bfee70ae6"
      },
      "source": [
        "tf(CORPUS, vocab)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[1, 1, 0, 0, 0, 0, 1, 2, 1],\n",
              " [1, 0, 0, 0, 1, 0, 1, 2, 1],\n",
              " [1, 0, 0, 1, 0, 1, 1, 2, 1],\n",
              " [1, 1, 1, 0, 0, 0, 1, 2, 1]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4eqJQQwxgw_U",
        "outputId": "5e7aadf8-dfa4-4630-a722-62c36294179b"
      },
      "source": [
        "vocab"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['the', 'first', '?', 'and', 'second', 'third', 'this', 'is', 'document']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jlijDYUF4x8T"
      },
      "source": [
        "def build_dtm(corpus: List[str]) -> pd.DataFrame:\n",
        "    ### TODO 2 ###\n",
        "    # build a vocabulary of the given corpus - use nested list comprehension, str.split(\" \"),  set,  and list\n",
        "    vocab: List[str] = list(set(sent for row in CORPUS for sent in row.split(\" \")))\n",
        "    ##############\n",
        "\n",
        "    ### TODO 3 ###\n",
        "    # populate a dtm - get use of the tf function\n",
        "    dtm: List[List[int]] = tf(CORPUS, vocab)\n",
        "    ##############\n",
        "    # return dtm as a pandas dataframe (for better visualization of the columns)\n",
        "    dtm = pd.DataFrame(data=dtm, columns=vocab)\n",
        "    return dtm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jm8iVvKu40KT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b7008c6-0d80-4500-ce24-252243dd0bea"
      },
      "source": [
        " # build a dtm from the corpus, and have a look at it\n",
        "dtm = build_dtm(CORPUS)\n",
        "print(dtm)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   the  first  ?  and  second  third  this  is  document\n",
            "0    1      1  0    0       0      0     1   2         1\n",
            "1    1      0  0    0       1      0     1   2         1\n",
            "2    1      0  0    1       0      1     1   2         1\n",
            "3    1      1  1    0       0      0     1   2         1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6c5HsuPK44TJ"
      },
      "source": [
        "다음과 같은 결과가 나와야 합니다 (단어의 순서는 달라도 괜찮습니다):\n",
        "```\n",
        "   is  ?  first  and  document  this  the  second  third\n",
        "0   2  0      1    0         1     1    1       0      0\n",
        "1   2  0      0    0         1     1    1       1      0\n",
        "2   2  0      0    1         1     1    1       0      1\n",
        "3   2  1      1    0         1     1    1       0      0\n",
        "```\n",
        "(슬라이드에는 0또는 1로 카운트를 했지만, 튜토리얼에서는 그냥 카운트를 하겠습니다! (e.g. is가 두 개 포함되어 있다면 그냥 2로)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k8W1mGQO454u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "999b9606-f583-4e27-f593-515da36473a7"
      },
      "source": [
        "# this will print out the similarities of the documents to each other\n",
        "sim_matrix = cosine_similarity(dtm.to_numpy(), dtm.to_numpy())\n",
        "print(sim_matrix)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1.         0.875      0.82495791 0.94280904]\n",
            " [0.875      1.         0.82495791 0.82495791]\n",
            " [0.82495791 0.82495791 1.         0.77777778]\n",
            " [0.94280904 0.82495791 0.77777778 1.        ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v5ox3YaN489-"
      },
      "source": [
        "다음과 같은 결과가 나와야 합니다:\n",
        "```\n",
        "[[1.         0.875      0.82495791 0.94280904]\n",
        " [0.875      1.         0.82495791 0.82495791]\n",
        " [0.82495791 0.82495791 1.         0.77777778]\n",
        " [0.94280904 0.82495791 0.77777778 1.        ]]\n",
        "```\n",
        "\n",
        "## **TODO 4**: 마지막으로, 다음의 질문에 답해주세요.\n",
        "> 위 `sim_matrix`를 보고 `dtm`의 어떤 문제를 발견할 수 있나요? (힌트: `CORPUS`에 있는 문장의 의미는 모두 동일한가요?)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "35LpccZV49Qj"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}